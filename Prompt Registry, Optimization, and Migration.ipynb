{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5fd8870-771f-44b9-86a8-024c8f190928",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade mlflow databricks-sdk dspy openai\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b06791d-79bc-47b3-9547-2f91229fb315",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Model Switching, not as easy as swapping prompts\n",
    "\n",
    "Below is a quickstart example that updates a prompt to a different model. It's a simple prompt **classify this query** so you will likely see larger improvements for more complex use cases. We will go from GPT-5 to Gemma 3/GPT-OSS-20B\n",
    "\n",
    "Ensure that you have access to the Databricks Foundation Model APIs to run this successfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f19481c-5f06-400c-a48a-61a4d7794813",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import openai\n",
    "from mlflow.genai.optimize import GepaPromptOptimizer\n",
    "from mlflow.genai.scorers import Correctness\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "#Change the catalog and schema to your catalog and schema \n",
    "catalog = \"main\"\n",
    "schema = \"default\"\n",
    "prompt_registry_name = \"new_prompt_registry\"\n",
    "prompt_location = f\"{catalog}.{schema}.{prompt_registry_name}\"\n",
    "\n",
    "openai_client = w.serving_endpoints.get_open_ai_client()\n",
    "\n",
    "# Register initial prompt\n",
    "prompt = mlflow.genai.register_prompt(\n",
    "    name=prompt_location,\n",
    "    template=\"classify this: {{query}}\",\n",
    ")\n",
    "\n",
    "\n",
    "# Define your prediction function\n",
    "def predict_fn(query: str) -> str:\n",
    "    prompt = mlflow.genai.load_prompt(f\"prompts:/{prompt_location}/1\")\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        model=\"databricks-gpt-5\",\n",
    "        # load prompt template using PromptVersion.format()\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt.format(query=query)}],\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5476832-99ed-46a4-a4ac-25ba502eefe5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Test your Function\n",
    "\n",
    "Observe how accurately the model can classify the input with a bare bones prompt. While accurate, it is not aligned to any task or use case we are looking for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70c34609-8e46-43d1-8a18-a41583618b99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "output = predict_fn(\"The emergence of HIV as a chronic condition means that people living with HIV are required to take more responsibility for the self-management of their condition , including making physical , emotional and social adjustments.\")\n",
    "\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4821951-bab2-4834-912f-78e2561f3834",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Optimizing against Data\n",
    "\n",
    "Now we will provide some data with expected responses and facts. This will help optimize our model to behave and output in a way that fits our use cases. \n",
    "\n",
    "In this case, we just want the model to output one word from a choice of five words. It should only output that word without any further explanation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90b5e769-4b41-42e7-8582-c9148aa9b56d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Training data with inputs and expected outputs\n",
    "dataset = [\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"The emergence of HIV as a chronic condition means that people living with HIV are required to take more responsibility for the self-management of their condition , including making physical , emotional and social adjustments.\"},\n",
    "        # \"outputs\": {\"response\": \"BACKGROUND\"},\n",
    "        \"expectations\": {\"expected_facts\": [\"Classification label must be 'CONCLUSIONS', 'RESULTS', 'METHODS', 'OBJECTIVE', 'BACKGROUND'\"]}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"The emergence of HIV as a chronic condition means that people living with HIV are required to take more responsibility for the self-management of their condition , including making physical , emotional and social adjustments.\"},\n",
    "        \"outputs\": {\"response\": \"BACKGROUND\"},\n",
    "        \"expectations\": {\"expected_response\": \"BACKGROUND\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"This paper describes the design and evaluation of Positive Outlook , an online program aiming to enhance the self-management skills of gay men living with HIV .\"},\n",
    "        # \"outputs\": {\"response\": \"BACKGROUND\"},\n",
    "        \"expectations\": {\"expected_facts\": [\"Classification label must be 'CONCLUSIONS', 'RESULTS', 'METHODS', 'OBJECTIVE', 'BACKGROUND'\"]}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"This paper describes the design and evaluation of Positive Outlook , an online program aiming to enhance the self-management skills of gay men living with HIV .\"},\n",
    "        \"outputs\": {\"response\": \"BACKGROUND\"},\n",
    "        \"expectations\": {\"expected_response\": \"BACKGROUND\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"This study is designed as a randomised controlled trial in which men living with HIV in Australia will be assigned to either an intervention group or usual care control group .\"},\n",
    "        # \"outputs\": {\"response\": \"METHODS\"},\n",
    "        \"expectations\": { \"expected_facts\": [\"Classification label must be 'CONCLUSIONS', 'RESULTS', 'METHODS', 'OBJECTIVE', 'BACKGROUND'\"]}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"This study is designed as a randomised controlled trial in which men living with HIV in Australia will be assigned to either an intervention group or usual care control group .\"},\n",
    "        \"outputs\": {\"response\": \"METHODS\"},\n",
    "        \"expectations\": {\"expected_response\": \"METHODS\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"The intervention group will participate in the online group program ` Positive Outlook ' .\"},\n",
    "        # \"outputs\": {\"response\": \"METHODS\"},\n",
    "        \"expectations\": {\"expected_facts\": [\"Classification label must be 'CONCLUSIONS', 'RESULTS', 'METHODS', 'OBJECTIVE', 'BACKGROUND'\"]}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"The intervention group will participate in the online group program ` Positive Outlook ' .\"},\n",
    "        \"outputs\": {\"response\": \"METHODS\"},\n",
    "        \"expectations\": {\"expected_response\": \"METHODS\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"The program is based on self-efficacy theory and uses a self-management approach to enhance skills , confidence and abilities to manage the psychosocial issues associated with HIV in daily life .\"},\n",
    "        # \"outputs\": {\"response\": \"METHODS\"},\n",
    "        \"expectations\": {\"expected_facts\": [\"Classification label must be 'CONCLUSIONS', 'RESULTS', 'METHODS', 'OBJECTIVE', 'BACKGROUND'\"]}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"The program is based on self-efficacy theory and uses a self-management approach to enhance skills , confidence and abilities to manage the psychosocial issues associated with HIV in daily life .\"},\n",
    "        \"outputs\": {\"response\": \"METHODS\"},\n",
    "        \"expectations\": {\"expected_response\": \"METHODS\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"Participants will access the program for a minimum of 90 minutes per week over seven weeks .\"},\n",
    "        # \"outputs\": {\"response\": \"METHODS\"},\n",
    "        \"expectations\": {\"expected_facts\": [\"Classification label must be 'CONCLUSIONS', 'RESULTS', 'METHODS', 'OBJECTIVE', 'BACKGROUND'\"]}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"Participants will access the program for a minimum of 90 minutes per week over seven weeks .\"},\n",
    "        \"outputs\": {\"response\": \"METHODS\"},\n",
    "        \"expectations\": {\"expected_response\": \"METHODS\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Optimize the prompt\n",
    "result = mlflow.genai.optimize_prompts(\n",
    "    predict_fn=predict_fn,\n",
    "    train_data=dataset,\n",
    "    prompt_uris=[prompt.uri],\n",
    "    optimizer=GepaPromptOptimizer(reflection_model=\"databricks:/databricks-gpt-5-2\"),\n",
    "    scorers=[Correctness(model=\"databricks:/databricks-gpt-5\")],\n",
    ")\n",
    "\n",
    "# Use the optimized prompt\n",
    "optimized_prompt = result.optimized_prompts[0]\n",
    "print(f\"Optimized template: {optimized_prompt.template}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25b10d5c-7e92-417f-9495-d6437bb26c99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Initial Score: {result.initial_eval_score}\\n\") \n",
    "print(f\"Final Score: {result.final_eval_score}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "425290a1-37cf-46b8-95b8-6d612a19803c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Let's review the Changes\n",
    "\n",
    "Let's test to see how gpt oss works now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8242533-7cbc-47b6-bc44-933104858f5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "def predict_fn(query: str) -> str:\n",
    "    prompt = mlflow.genai.load_prompt(f\"prompts:/{prompt_location}/2\") \n",
    "    # updated_prompt = f\"{prompt}\\n\\nclassify this: {{query}}\"\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        # model=\"databricks-gemma-3-12b\",\n",
    "        # model = \"databricks-gpt-oss-20b\",\n",
    "        model = \"databricks-gpt-5\",\n",
    "        # load prompt template using PromptVersion.format()\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt.format(query=query)}]\n",
    "            # {\"role\": \"user\", \"content\": query}],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60b05b33-c5cf-4c88-8b05-dd45c527fb7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output = predict_fn(query=\"Orbital steroid injection for thyroid-related ophthalmopathy is effective and safe .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fb2b59e-9b07-437f-bd9c-fcdf39bd4d8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#right answer: RESULTS\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3087776-ecbd-46c9-aad8-2d6d8b03ccac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Let's try it with Gemma\n",
    "\n",
    "How well does it do with this prompt? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6915c847-41a7-4b9b-8011-01bb894bbd79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "prompt = mlflow.genai.load_prompt(f\"prompts:/{prompt_location}/2\")\n",
    "\n",
    "Markdown(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63761737-e891-469d-8579-26bee83db50c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predict_fn_gemma(query: str) -> str:\n",
    "    prompt = mlflow.genai.load_prompt(f\"prompts:/{prompt_location}/2\")\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        model=\"databricks-gemma-3-12b\",\n",
    "        # model = \"databricks-gpt-oss-20b\",\n",
    "        # model = \"databricks-gpt-5\",\n",
    "        # load prompt template using PromptVersion.format()\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt.format(query=query)},\n",
    "            {\"role\": \"user\", \"content\": query}],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "593f4dd2-b864-4472-84af-781c42ac883b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output = predict_fn_gemma(query=\"Orbital steroid injection for thyroid-related ophthalmopathy is effective and safe .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "876fd0b8-ba44-4210-99d1-b2f208e756c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#right answer: Results\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "464b9853-edf9-406e-8629-cd50c2123831",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Not correct, Not Surprising\n",
    "\n",
    "While we did switch to a smaller model, we can see it's not as simple as just giving it an optimized prompt and see the same performance improvements. \n",
    "\n",
    "We should reoptimize for a new prompt for the new model on the original prompt. \n",
    "\n",
    "Let's do it below. I'll set up a new function to hit the gemma 3 model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23a3a6c6-7f3f-4d8c-bd1b-5e70e9b3cc2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predict_fn_gemma(query: str) -> str:\n",
    "    prompt = mlflow.genai.load_prompt(f\"prompts:/{prompt_location}/1\")\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        model=\"databricks-gemma-3-12b\",\n",
    "        # load prompt template using PromptVersion.format()\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt.format(query=query)}],\n",
    "    )\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "add02d04-6a9f-4b71-ab2e-a5b67e50fe00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_gemma_oss = mlflow.genai.optimize_prompts(\n",
    "    predict_fn=predict_fn_gemma,\n",
    "    train_data=dataset,\n",
    "    prompt_uris=[prompt.uri],\n",
    "    optimizer=GepaPromptOptimizer(reflection_model=\"databricks:/databricks-gpt-5-2\"),\n",
    "    scorers=[Correctness(model=\"databricks:/databricks-gpt-5\")],\n",
    ")\n",
    "# Use the optimized prompt\n",
    "optimized_prompt = result.optimized_prompts[0]\n",
    "print(f\"Optimized template: {optimized_prompt.template}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32097e76-7037-4af1-87c0-70c3f86b7752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#We should already have decent scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2402e636-b97c-4ede-b617-8a6229c6fde0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Initial Score: {result_gemma_oss.initial_eval_score}\\n\") \n",
    "print(f\"Final Score: {result_gemma_oss.final_eval_score}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee292247-df24-4970-b8b9-e7d56b0462c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "prompt = mlflow.genai.load_prompt(f\"prompts:/{prompt_location}/3\")\n",
    "\n",
    "Markdown(prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "300cbab3-9fcc-4fda-8869-4ba7500844c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Let's check again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7977650-b46e-4172-8b36-a5adc5f0011e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predict_fn_gemma_updated(query: str) -> str:\n",
    "    prompt = mlflow.genai.load_prompt(f\"prompts:/{prompt_location}/3\")\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        model=\"databricks-gemma-3-12b\",\n",
    "        # model = \"databricks-gpt-oss-20b\",\n",
    "        # model = \"databricks-gpt-5\",\n",
    "        # load prompt template using PromptVersion.format()\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt.format(query=query)},\n",
    "            {\"role\": \"user\", \"content\": query}],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25431af6-7fc0-41ff-9bdf-3cc63185bca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output = predict_fn_gemma_updated(query=\"Orbital steroid injection for thyroid-related ophthalmopathy is effective and safe .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72b628c7-5ef8-41fb-9553-5109195c23db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#right answer: RESULTS\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00fb91b0-bcb1-4e94-b14a-1e18834f189f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Is it now correct? \n",
    "\n",
    "We can't assume the existing prompt will work for all models or be performant for all models. It only takes a few minutes to re-optimize the model! \n",
    "\n",
    "Let's go back to our experiment to add some aliases.\n",
    "\n",
    "Now we can use mlflow prompt registry to load the right prompts depending on the model we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aadca5c-259f-4cad-a0fa-5bf26d37c695",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#GPT-OSS 20B\n",
    "\n",
    "def predict_fn(query: str) -> str:\n",
    "    prompt = mlflow.genai.load_prompt(f\"prompts:/{prompt_location}@gpt_oss_20b\")\n",
    "    # updated_prompt = f\"{prompt}\\n\\nclassify this: {{query}}\"\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        # model=\"databricks-gemma-3-12b\",\n",
    "        model = \"databricks-gpt-oss-20b\",\n",
    "        # model = \"databricks-gpt-5\",\n",
    "        # load prompt template using PromptVersion.format()\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt.format(query=query)}]\n",
    "            # {\"role\": \"user\", \"content\": query}],\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "output = predict_fn(query=\"Orbital steroid injection for thyroid-related ophthalmopathy is effective and safe .\")\n",
    "output[1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd199318-29ff-471f-8cc3-7b8d7c09f18f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#GPT-5\n",
    "\n",
    "def predict_fn(query: str) -> str:\n",
    "    prompt = mlflow.genai.load_prompt(f\"prompts:/{prompt_location}@gpt_oss_20b\")\n",
    "    # prompt = mlflow.genai.load_prompt(f\"prompts:/{prompt_location}@gpt_5\")\n",
    "    # updated_prompt = f\"{prompt}\\n\\nclassify this: {{query}}\"\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        # model=\"databricks-gemma-3-12b\",\n",
    "        # model = \"databricks-gpt-oss-20b\",\n",
    "        model = \"databricks-gpt-5\",\n",
    "        # load prompt template using PromptVersion.format()\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt.format(query=query)}]\n",
    "            # {\"role\": \"user\", \"content\": query}],\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "output = predict_fn(query=\"Orbital steroid injection for thyroid-related ophthalmopathy is effective and safe .\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f2bdb45-c204-42a6-9b39-9acdfaa67781",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#GPT5\n",
    "\n",
    "def predict_fn_gemma(query: str) -> str:\n",
    "    prompt = mlflow.genai.load_prompt(f\"prompts:/{prompt_location}@gpt5\")\n",
    "    # updated_prompt = f\"{prompt}\\n\\nclassify this: {{query}}\"\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        model=\"databricks-gemma-3-12b\",\n",
    "        # model = \"databricks-gpt-oss-20b\",\n",
    "        # model = \"databricks-gpt-5\",\n",
    "        # load prompt template using PromptVersion.format()\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt.format(query=query)},\n",
    "            {\"role\": \"user\", \"content\": query}],\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "output = predict_fn_gemma(query=\"Orbital steroid injection for thyroid-related ophthalmopathy is effective and safe .\")\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Prompt Registry, Optimization, and Migration",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}